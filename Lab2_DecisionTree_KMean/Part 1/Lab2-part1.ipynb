{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 2, Part 1 - Decision Tree & Random Forest\n",
    "\n",
    "## Lab Instruction \n",
    "\n",
    "In this lab, you are to create a Decision Tree and Random Forest model  to predict the sale price of houses **SalePrice = (Low, Medium, High)** from a given set of attributes. <br>\n",
    "\n",
    "The data file is`lab2_dataset.csv` <br>\n",
    "\n",
    "Note that you need to explore and process/drop attributes, <br>\n",
    "and map numerical values of sale prices to categorical values (Low, Medium, High)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  1. Import the Dataset and Learn About the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.23.4\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"lab2_dataset.csv\")\n",
    "print(pd.__version__) # You should use version 0.21+"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NA Percentage(%)\n",
      "Id                0.000000\n",
      "MSSubClass        0.000000\n",
      "MSZoning          0.000000\n",
      "LotFrontage      17.739726\n",
      "LotArea           0.000000\n",
      "Street            0.000000\n",
      "Alley            93.767123\n",
      "LotShape          0.000000\n",
      "LandContour       0.000000\n",
      "Utilities         0.000000\n",
      "LotConfig         0.000000\n",
      "LandSlope         0.000000\n",
      "Neighborhood      0.000000\n",
      "Condition1        0.000000\n",
      "Condition2        0.000000\n",
      "BldgType          0.000000\n",
      "HouseStyle        0.000000\n",
      "OverallQual       0.000000\n",
      "OverallCond       0.000000\n",
      "YearBuilt         0.000000\n",
      "YearRemodAdd      0.000000\n",
      "RoofStyle         0.000000\n",
      "RoofMatl          0.000000\n",
      "Exterior1st       0.000000\n",
      "Exterior2nd       0.000000\n",
      "MasVnrType        0.547945\n",
      "MasVnrArea        0.547945\n",
      "ExterQual         0.000000\n",
      "ExterCond         0.000000\n",
      "Foundation        0.000000\n",
      "BsmtQual          2.534247\n",
      "BsmtCond          2.534247\n",
      "BsmtExposure      2.602740\n",
      "BsmtFinType1      2.534247\n",
      "BsmtFinSF1        0.000000\n",
      "BsmtFinType2      2.602740\n",
      "BsmtFinSF2        0.000000\n",
      "BsmtUnfSF         0.000000\n",
      "TotalBsmtSF       0.000000\n",
      "Heating           0.000000\n",
      "HeatingQC         0.000000\n",
      "CentralAir        0.000000\n",
      "Electrical        0.068493\n",
      "1stFlrSF          0.000000\n",
      "2ndFlrSF          0.000000\n",
      "LowQualFinSF      0.000000\n",
      "GrLivArea         0.000000\n",
      "BsmtFullBath      0.000000\n",
      "BsmtHalfBath      0.000000\n",
      "FullBath          0.000000\n",
      "HalfBath          0.000000\n",
      "BedroomAbvGr      0.000000\n",
      "KitchenAbvGr      0.000000\n",
      "KitchenQual       0.000000\n",
      "TotRmsAbvGrd      0.000000\n",
      "Functional        0.000000\n",
      "Fireplaces        0.000000\n",
      "FireplaceQu      47.260274\n",
      "GarageType        5.547945\n",
      "GarageYrBlt       5.547945\n",
      "GarageFinish      5.547945\n",
      "GarageCars        0.000000\n",
      "GarageArea        0.000000\n",
      "GarageQual        5.547945\n",
      "GarageCond        5.547945\n",
      "PavedDrive        0.000000\n",
      "WoodDeckSF        0.000000\n",
      "OpenPorchSF       0.000000\n",
      "EnclosedPorch     0.000000\n",
      "3SsnPorch         0.000000\n",
      "ScreenPorch       0.000000\n",
      "PoolArea          0.000000\n",
      "PoolQC           99.520548\n",
      "Fence            80.753425\n",
      "MiscFeature      96.301370\n",
      "MiscVal           0.000000\n",
      "MoSold            0.000000\n",
      "YrSold            0.000000\n",
      "SaleType          0.000000\n",
      "SaleCondition     0.000000\n",
      "SalePrice         0.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "pd.options.display.max_rows = None\n",
    "print(\"NA Percentage(%)\")\n",
    "print((df.isna().sum()/df.shape[0])*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_rows = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2. Preprocessing\n",
    "Try to think about what data's feature that the model accept and how the model compute those data. Then use techniques that you have learned to preprocess the data. \n",
    "\n",
    "**For example:** \n",
    "-  Remove non-informative features\n",
    "-  Remove features with too many NA\n",
    "-  Remove rows with incomplete data\n",
    "-  Remove features with highly unbalanced labels\n",
    "-  Encode categorical variables as appropriate\n",
    "\n",
    "Then, create one dataframe for the features and another frame for the output variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_noninfo = df.drop(columns = ['Id'],axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_many_na_col = drop_noninfo.drop(columns = ['Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis = 1)\n",
    "# drop_many_na_col.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1094, 75)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_many_na_row = drop_many_na_col.dropna(how='any')\n",
    "drop_many_na_row.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1094 entries, 0 to 1459\n",
      "Columns: 260 entries, MSSubClass to SaleCondition_Partial\n",
      "dtypes: float64(3), int64(34), uint8(223)\n",
      "memory usage: 563.0 KB\n"
     ]
    }
   ],
   "source": [
    "# Encode with one hot\n",
    "data_encode_onehot =  pd.get_dummies(drop_many_na_row) \n",
    "data_encode_onehot.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1094, 261)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_encode_onehot['SaleLevel'] = pd.qcut(data_encode_onehot['SalePrice'], q=[0,0.33,0.66,1], labels=['Low','Median','High'])\n",
    "data_encode_onehot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1094, 260)\n"
     ]
    }
   ],
   "source": [
    "cleaned_dataset = data_encode_onehot.drop(columns = ['SalePrice'],axis = 1)\n",
    "print(cleaned_dataset.shape)\n",
    "# for i in cleaned_dataset.columns:\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_x = cleaned_dataset.drop(columns = ['SaleLevel'],axis=1).copy()\n",
    "dataset_y = cleaned_dataset.SaleLevel.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset_x,dataset_y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier\n",
    "\n",
    "Use both Hold-out and K-fold CV to evaluate your model\n",
    "\n",
    "Analyze the model results. Do you think the model is good enough? <br>\n",
    "Does it overfit or underfit the data? <br>\n",
    "Explain and provide evidence to support your claims.\n",
    "Look at various classification matrix of train and test sets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier \n",
    "\n",
    "dt_clf = DecisionTreeClassifier() \n",
    "dt_clf = dt_clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_train = dt_clf.predict(x_train) \n",
    "yhat_train_prob = dt_clf.predict_proba(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_test = dt_clf.predict(x_test) \n",
    "yhat_test_prob = dt_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Hold-out evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and analyse the result using classification_report module and confusion matrix\n",
    "- See http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 1.0\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       High       1.00      1.00      1.00       296\n",
      "        Low       1.00      1.00      1.00       295\n",
      "     Median       1.00      1.00      1.00       284\n",
      "\n",
      "avg / total       1.00      1.00      1.00       875\n",
      "\n",
      "Confusion Matrix\n",
      "[[295   0   0]\n",
      " [  0 284   0]\n",
      " [  0   0 296]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "print('Train Accuracy: %s'%accuracy_score(y_train, yhat_train))\n",
    "print(classification_report(y_train, yhat_train))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_train, yhat_train , labels=[\"Low\", \"Median\",\"High\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 78.99543378995433\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       High       0.84      0.85      0.85        75\n",
      "        Low       0.79      0.90      0.84        69\n",
      "     Median       0.72      0.63      0.67        75\n",
      "\n",
      "avg / total       0.79      0.79      0.79       219\n",
      "\n",
      "Confusion Matrix\n",
      "[[62  7  0]\n",
      " [16 47 12]\n",
      " [ 0 11 64]]\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %s'%(accuracy_score(y_test, yhat_test)*100))\n",
    "print(classification_report(y_test, yhat_test))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, yhat_test , labels=[\"Low\", \"Median\",\"High\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize  Tree \n",
    "- We will use https://github.com/xflr6/graphviz\n",
    "\n",
    "To install this package, type the following command in the Anaconda Prompt.\n",
    "\n",
    "```conda install -c conda-forge graphviz python-graphviz ```\n",
    "\n",
    "Run the following cell to visualize your graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'tree.pdf'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import graphviz\n",
    "from sklearn import tree\n",
    "dot_data = tree.export_graphviz(dt_clf, out_file=None,\n",
    "                                feature_names=x_train.columns,\n",
    "                                class_names=['Low','Median','High'], \n",
    "                                filled=True, \n",
    "                                rounded=True, \n",
    "                                special_characters=True, \n",
    "                                proportion=True)\n",
    "graph = graphviz.Source(dot_data) \n",
    "graph.render(\"tree\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output from the code above is a pdf file that have a visualization of your decision tree model. Open the pdf file and analyse your model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 K-Fold CV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.74431818 0.74431818 0.76       0.74712644 0.70689655]\n",
      "5-Fold Cross Validation Accuracy : 0.7405\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "dt_score_train = cross_val_score(DecisionTreeClassifier(), x_train, y_train, cv = 5)\n",
    "print(dt_score_train)\n",
    "print(\"5-Fold Cross Validation Accuracy : %1.4f\" % dt_score_train.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.6        0.68181818 0.63636364 0.70454545 0.61904762]\n",
      "5-Fold Cross Validation Accuracy : 0.6484\n"
     ]
    }
   ],
   "source": [
    "dt_score_test = cross_val_score(DecisionTreeClassifier(), x_test, y_test, cv = 5)\n",
    "print(dt_score_test)\n",
    "print(\"5-Fold Cross Validation Accuracy : %1.4f\" % dt_score_test.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier\n",
    "\n",
    "Use both Hold-out and K-fold CV to evaluate the classifier. \n",
    "\n",
    "Analyze the model results. \n",
    "- Do you think the model is good enough? Does it overfit or underfit the data? \n",
    "- How does it perform compared to basic decision tree classifier ? <br>\n",
    "\n",
    "Explain and provide evidence to support your claims."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier \n",
    "rf_clf = RandomForestClassifier() \n",
    "rf_clf = rf_clf.fit(x_train, y_train) \n",
    "rf_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yrf_train_pred = rf_clf.predict(x_train) \n",
    "yrf_train_prob = rf_clf.predict_proba(x_train)\n",
    "\n",
    "yrf_test_pred = rf_clf.predict(x_test) \n",
    "yrf_test_prob = rf_clf.predict_proba(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Hold-out evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate and analyse your result using classification_report module and confusion matrix\n",
    "- See http://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 0.9931428571428571\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       High       1.00      1.00      1.00       292\n",
      "        Low       0.99      1.00      0.99       293\n",
      "     Median       1.00      0.98      0.99       290\n",
      "\n",
      "avg / total       0.99      0.99      0.99       875\n",
      "\n",
      "Confusion Matrix\n",
      "[[293   0   0]\n",
      " [  4 285   1]\n",
      " [  0   1 291]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "\n",
    "print('Train Accuracy: %s'%accuracy_score(y_train, yrf_train_pred))\n",
    "print(classification_report(y_train, yrf_train_pred))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_train, yrf_train_pred , labels=[\"Low\", \"Median\",\"High\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7488584474885844\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "       High       0.85      0.86      0.86        79\n",
      "        Low       0.75      0.83      0.79        71\n",
      "     Median       0.62      0.54      0.57        69\n",
      "\n",
      "avg / total       0.74      0.75      0.74       219\n",
      "\n",
      "Confusion Matrix\n",
      "[[59 12  0]\n",
      " [20 37 12]\n",
      " [ 0 11 68]]\n"
     ]
    }
   ],
   "source": [
    "print('Test Accuracy: %s'%accuracy_score(y_test, yrf_test_pred))\n",
    "print(classification_report(y_test, yrf_test_pred))\n",
    "print('Confusion Matrix')\n",
    "print(confusion_matrix(y_test, yrf_test_pred , labels=[\"Low\", \"Median\",\"High\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 K-Fold CV with accuracy metric\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80113636 0.77840909 0.85142857 0.78735632 0.81609195]\n",
      "5-Fold Cross Validation Accuracy : 0.8069\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "scoreTrain = cross_val_score(RandomForestClassifier(), x_train, y_train, cv = 5)\n",
    "print(scoreTrain) \n",
    "print(\"5-Fold Cross Validation Accuracy : %1.4f\" % scoreTrain.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66666667 0.68181818 0.72727273 0.68181818 0.71428571]\n",
      "5-Fold Cross Validation Accuracy : 0.6944\n"
     ]
    }
   ],
   "source": [
    "scoreTest = cross_val_score(RandomForestClassifier(), x_test, y_test, cv = 5)\n",
    "print(scoreTest) \n",
    "print(\"5-Fold Cross Validation Accuracy : %1.4f\" % scoreTest.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Evaluate using multiple metrics\n",
    "- precision: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.precision_score.html\n",
    "- recall: http://scikit-learn.org/stable/modules/generated/sklearn.metrics.recall_score.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision[train]\t[0.99657534 0.98653199 0.9965035 ]\n",
      "Recal[train]:\t\t[0.99657534 1.         0.98275862]\n",
      "Precision[test]\t\t[0.85       0.74683544 0.61666667]\n",
      "Recal[test]:\t\t[0.86075949 0.83098592 0.53623188]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score,recall_score\n",
    "print('Precision[train]'+\"\\t\"+str(precision_score(y_train, yrf_train_pred, average=None))) \n",
    "print(\"Recal[train]:\" + \"\\t\\t\"+str(recall_score(y_train, yrf_train_pred, average=None)))\n",
    "print('Precision[test]'+\"\\t\\t\"+str(precision_score(y_test, yrf_test_pred, average=None))) \n",
    "print(\"Recal[test]:\" + \"\\t\\t\"+str(recall_score(y_test, yrf_test_pred, average=None)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Parameter Tuning using GridSearch\n",
    "\n",
    "Try grid search on parameters max_depth, max_features, and n_estimators.\n",
    "Determine which parameter set  achieve the best result. <br>\n",
    "\n",
    "\n",
    "- See more: http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split0_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split1_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('split2_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('mean_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n",
      "D:\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:122: FutureWarning: You are accessing a training score ('std_train_score'), which will not be available by default any more in 0.21. If you need training scores, please set return_train_score=True\n",
      "  warnings.warn(*warn_args, **warn_kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_max_depth</th>\n",
       "      <th>param_max_features</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.017483</td>\n",
       "      <td>0.002307</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>4.052337e-07</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 10}</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.818493</td>\n",
       "      <td>0.803448</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.032195</td>\n",
       "      <td>1</td>\n",
       "      <td>0.893471</td>\n",
       "      <td>0.852487</td>\n",
       "      <td>0.878632</td>\n",
       "      <td>0.874863</td>\n",
       "      <td>0.016942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.016612</td>\n",
       "      <td>0.000464</td>\n",
       "      <td>0.002004</td>\n",
       "      <td>1.365593e-05</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 10}</td>\n",
       "      <td>0.740614</td>\n",
       "      <td>0.794521</td>\n",
       "      <td>0.831034</td>\n",
       "      <td>0.788571</td>\n",
       "      <td>0.037142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.951890</td>\n",
       "      <td>0.938250</td>\n",
       "      <td>0.935043</td>\n",
       "      <td>0.941728</td>\n",
       "      <td>0.007304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.020267</td>\n",
       "      <td>0.002863</td>\n",
       "      <td>0.002661</td>\n",
       "      <td>9.441457e-04</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 10}</td>\n",
       "      <td>0.774744</td>\n",
       "      <td>0.767123</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.763429</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>3</td>\n",
       "      <td>0.810997</td>\n",
       "      <td>0.778731</td>\n",
       "      <td>0.806838</td>\n",
       "      <td>0.798855</td>\n",
       "      <td>0.014331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.015286</td>\n",
       "      <td>0.000949</td>\n",
       "      <td>0.002343</td>\n",
       "      <td>4.722527e-04</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 7, 'max_features': 5}</td>\n",
       "      <td>0.754266</td>\n",
       "      <td>0.773973</td>\n",
       "      <td>0.748276</td>\n",
       "      <td>0.758857</td>\n",
       "      <td>0.010973</td>\n",
       "      <td>4</td>\n",
       "      <td>0.927835</td>\n",
       "      <td>0.886792</td>\n",
       "      <td>0.876923</td>\n",
       "      <td>0.897184</td>\n",
       "      <td>0.022045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.025912</td>\n",
       "      <td>0.002141</td>\n",
       "      <td>0.003012</td>\n",
       "      <td>1.415787e-03</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 5, 'max_features': 5}</td>\n",
       "      <td>0.744027</td>\n",
       "      <td>0.739726</td>\n",
       "      <td>0.703448</td>\n",
       "      <td>0.729143</td>\n",
       "      <td>0.018176</td>\n",
       "      <td>5</td>\n",
       "      <td>0.835052</td>\n",
       "      <td>0.787307</td>\n",
       "      <td>0.813675</td>\n",
       "      <td>0.812011</td>\n",
       "      <td>0.019527</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.017967</td>\n",
       "      <td>0.004959</td>\n",
       "      <td>0.001992</td>\n",
       "      <td>4.440535e-06</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>{'max_depth': 3, 'max_features': 5}</td>\n",
       "      <td>0.699659</td>\n",
       "      <td>0.743151</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.714286</td>\n",
       "      <td>0.020429</td>\n",
       "      <td>6</td>\n",
       "      <td>0.745704</td>\n",
       "      <td>0.744425</td>\n",
       "      <td>0.757265</td>\n",
       "      <td>0.749132</td>\n",
       "      <td>0.005775</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.017483      0.002307         0.001995    4.052337e-07   \n",
       "5       0.016612      0.000464         0.002004    1.365593e-05   \n",
       "1       0.020267      0.002863         0.002661    9.441457e-04   \n",
       "4       0.015286      0.000949         0.002343    4.722527e-04   \n",
       "2       0.025912      0.002141         0.003012    1.415787e-03   \n",
       "0       0.017967      0.004959         0.001992    4.440535e-06   \n",
       "\n",
       "  param_max_depth param_max_features                                params  \\\n",
       "3               5                 10  {'max_depth': 5, 'max_features': 10}   \n",
       "5               7                 10  {'max_depth': 7, 'max_features': 10}   \n",
       "1               3                 10  {'max_depth': 3, 'max_features': 10}   \n",
       "4               7                  5   {'max_depth': 7, 'max_features': 5}   \n",
       "2               5                  5   {'max_depth': 5, 'max_features': 5}   \n",
       "0               3                  5   {'max_depth': 3, 'max_features': 5}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  mean_test_score  \\\n",
       "3           0.744027           0.818493           0.803448         0.788571   \n",
       "5           0.740614           0.794521           0.831034         0.788571   \n",
       "1           0.774744           0.767123           0.748276         0.763429   \n",
       "4           0.754266           0.773973           0.748276         0.758857   \n",
       "2           0.744027           0.739726           0.703448         0.729143   \n",
       "0           0.699659           0.743151           0.700000         0.714286   \n",
       "\n",
       "   std_test_score  rank_test_score  split0_train_score  split1_train_score  \\\n",
       "3        0.032195                1            0.893471            0.852487   \n",
       "5        0.037142                1            0.951890            0.938250   \n",
       "1        0.011114                3            0.810997            0.778731   \n",
       "4        0.010973                4            0.927835            0.886792   \n",
       "2        0.018176                5            0.835052            0.787307   \n",
       "0        0.020429                6            0.745704            0.744425   \n",
       "\n",
       "   split2_train_score  mean_train_score  std_train_score  \n",
       "3            0.878632          0.874863         0.016942  \n",
       "5            0.935043          0.941728         0.007304  \n",
       "1            0.806838          0.798855         0.014331  \n",
       "4            0.876923          0.897184         0.022045  \n",
       "2            0.813675          0.812011         0.019527  \n",
       "0            0.757265          0.749132         0.005775  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {'max_depth':[3,5,7], 'max_features':[5, 10]} \n",
    "clf = GridSearchCV(RandomForestClassifier(), param_grid) \n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "s = pd.DataFrame(clf.cv_results_) \n",
    "s.sort_values('mean_test_score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.714 (+/-0.041) for {'max_depth': 3, 'max_features': 5}\n",
      "0.763 (+/-0.022) for {'max_depth': 3, 'max_features': 10}\n",
      "0.729 (+/-0.036) for {'max_depth': 5, 'max_features': 5}\n",
      "0.789 (+/-0.064) for {'max_depth': 5, 'max_features': 10}\n",
      "0.759 (+/-0.022) for {'max_depth': 7, 'max_features': 5}\n",
      "0.789 (+/-0.074) for {'max_depth': 7, 'max_features': 10}\n",
      "\n",
      "{'max_depth': 5, 'max_features': 10} 0.7885714285714286\n"
     ]
    }
   ],
   "source": [
    "means = clf.cv_results_['mean_test_score']\n",
    "stds = clf.cv_results_['std_test_score']\n",
    "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
    "    print(\"%0.3f (+/-%0.03f) for %r\"\n",
    "              % (mean, std * 2, params))\n",
    "print()\n",
    "print(clf.best_params_, clf.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
